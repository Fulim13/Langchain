{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: L3_function_calling.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Function Calling\n",
    "\n",
    "1. Designing sophisticated chat bots\n",
    "\n",
    "- Capable of organizing and managing schedules. For example, you can define a function to schedule a meeting: schedule_meeting(date: str, time: str,\n",
    "  attendees: List[str]).\n",
    "\n",
    "2. Convert natural language into actionable API calls\n",
    "\n",
    "- A command like “Turn on the hallway lights” can be converted to control_device(device: str, action: 'on' | 'off') for interacting with your home automation API.\n",
    "\n",
    "3. Extracting structured data\n",
    "\n",
    "- This could be done by defining a function such as extract_con textual_data(context: str, data_points: List[str]) or search_database(query: str).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def schedule_meeting(date, time, attendees):\n",
    "    # Connect to calendar service:\n",
    "    return {\n",
    "        \"event_id\": \"1234\",\n",
    "        \"status\": \"Meeting scheduled successfully!\",\n",
    "        \"date\": date,\n",
    "        \"time\": time,\n",
    "        \"attendees\": attendees\n",
    "    }\n",
    "\n",
    "\n",
    "def weather_search(code):\n",
    "    # Connect to weather service:\n",
    "    return {\n",
    "        \"location_code\": code,\n",
    "        \"temperature\": \"25°C\",\n",
    "        \"humidity\": \"60%\",\n",
    "        \"condition\": \"Sunny\"\n",
    "    }\n",
    "\n",
    "\n",
    "OPENAI_FUNCTIONS = {\n",
    "    \"schedule_meeting\": schedule_meeting,\n",
    "    \"weather_search\": weather_search\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'schedule_meeting', 'description': 'Set a meeting at a specified date and time for designated attendees', 'parameters': {'type': 'object', 'properties': {'date': {'description': 'date of the meeting', 'type': 'string'}, 'time': {'description': 'time of the meeting', 'type': 'string'}, 'attendees': {'description': 'attendees for the meeting', 'type': 'array', 'items': {'type': 'string'}}}, 'required': ['date', 'time', 'attendees']}}}, {'type': 'function', 'function': {'name': 'weather_search', 'description': 'Search for weather information based on location code', 'parameters': {'type': 'object', 'properties': {'code': {'description': 'country code', 'type': 'string'}}, 'required': ['code']}}}]\n"
     ]
    }
   ],
   "source": [
    "class schedule_meeting(BaseModel):\n",
    "    \"\"\"Set a meeting at a specified date and time for designated attendees\"\"\"\n",
    "    date: str = Field(description=\"date of the meeting\")\n",
    "    time: str = Field(description=\"time of the meeting\")\n",
    "    attendees: List[str] = Field(description=\"attendees for the meeting\")\n",
    "\n",
    "\n",
    "class weather_search(BaseModel):\n",
    "    \"\"\"Search for weather information based on location code\"\"\"\n",
    "    code: str = Field(description=\"country code\")\n",
    "\n",
    "\n",
    "schedule_meeting_function = convert_to_openai_function(schedule_meeting)\n",
    "weather_search_function = convert_to_openai_function(weather_search)\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": schedule_meeting_function\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": weather_search_function\n",
    "    }\n",
    "]\n",
    "\n",
    "print(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_chRvzbp5mG1PQsiEdjVBdFND', function=Function(arguments='{\"date\": \"2023-11-01\", \"time\": \"14:00\", \"attendees\": [\"Alice\", \"Bob\"]}', name='schedule_meeting'), type='function'), ChatCompletionMessageToolCall(id='call_pSCSVaSvRCioipGDtY51P3qk', function=Function(arguments='{\"date\": \"2023-11-02\", \"time\": \"15:00\", \"attendees\": [\"Charlie\", \"Dave\"]}', name='schedule_meeting'), type='function'), ChatCompletionMessageToolCall(id='call_dg51BYV3UkjDNuWRi9Gnx1K6', function=Function(arguments='{\"code\": \"MY\"}', name='weather_search'), type='function')], refusal=None)\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": '''Schedule a meeting on 2023-11-01 at 14:00 with Alice and Bob Then I want to schedule another meeting on 2023-11-02 at 15:00 with Charlie and Dave. Lastly, Help me to check weather for code \"MY\" '''\n",
    "    }\n",
    "]\n",
    "\n",
    "# Send the conversation and function schema to the model:\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=functions\n",
    ")\n",
    "\n",
    "response = response.choices[0].message\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the function name:  schedule_meeting\n",
      "These are the function arguments:  {'date': '2023-11-01', 'time': '14:00', 'attendees': ['Alice', 'Bob']}\n",
      "This is the function name:  schedule_meeting\n",
      "These are the function arguments:  {'date': '2023-11-02', 'time': '15:00', 'attendees': ['Charlie', 'Dave']}\n",
      "This is the function name:  weather_search\n",
      "These are the function arguments:  {'code': 'MY'}\n",
      "I have successfully scheduled the meetings as requested:\n",
      "\n",
      "1. Meeting with Alice and Bob on 2023-11-01 at 14:00.\n",
      "2. Meeting with Charlie and Dave on 2023-11-02 at 15:00.\n",
      "\n",
      "The weather for location code \"MY\" is 25°C with 60% humidity and sunny conditions.\n"
     ]
    }
   ],
   "source": [
    "# Check if the model wants to call our function:\n",
    "if response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        # Get the function name and arguments to call:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        print(\"This is the function name: \", function_name)\n",
    "        print(\"These are the function arguments: \", function_args)\n",
    "\n",
    "        function = OPENAI_FUNCTIONS.get(function_name)\n",
    "\n",
    "        if not function:\n",
    "            raise Exception(f\"Function {function_name} not found.\")\n",
    "\n",
    "        # Call the function:\n",
    "        function_response = function(**function_args)\n",
    "\n",
    "        # Share the function's response with the model:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(function_response),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Let the model generate a user-friendly response:\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages\n",
    "    )\n",
    "\n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json.loads() and json.dumps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 30, 'is_student': False}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_string = '{\"name\": \"Alice\", \"age\": 30, \"is_student\": false}'\n",
    "# Convert JSON to Python dictionary\n",
    "python_dict = json.loads(json_string)\n",
    "\n",
    "print(python_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Alice\", \"age\": 30, \"is_student\": false}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "python_dict = {\"name\": \"Alice\", \"age\": 30, \"is_student\": False}\n",
    "\n",
    "# Convert Python dictionary to JSON\n",
    "json_string = json.dumps(python_dict)\n",
    "\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling in LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Article(points='the growing interest in AI adoption in various industries', contrarian_points=None, author='Dr. Jane Smith')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Article(BaseModel):\n",
    "    \"\"\"Identifying key points and contrarian views in an article.\"\"\"\n",
    "    points: str = Field(..., description=\"Key points from the article\")\n",
    "    contrarian_points: Optional[str] = Field(\n",
    "        None, description=\"Any contrarian points acknowledged in the article\"\n",
    "    )\n",
    "    author: Optional[str] = Field(None, description=\"Author of the article\")\n",
    "\n",
    "\n",
    "_EXTRACTION_TEMPLATE = \"\"\"Extract and save the relevant entities mentioned \\\n",
    "in the following passage together with their properties.\n",
    "If a property is not present and is not required in the function parameters,\n",
    "do not include it in the output.\"\"\"\n",
    "\n",
    "# Create a prompt telling the LLM to extract information:\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    {(\"system\", _EXTRACTION_TEMPLATE), (\"user\", \"{input}\")}\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "pydantic_schemas = [Article]\n",
    "\n",
    "# Convert Pydantic objects to the appropriate schema:\n",
    "tools = [convert_to_openai_tool(p) for p in pydantic_schemas]\n",
    "\n",
    "# Give the model access to these tools:\n",
    "model = model.bind_tools(tools=tools)\n",
    "\n",
    "# Create an end to end chain:\n",
    "chain = prompt | model | PydanticToolsParser(tools=pydantic_schemas)\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"input\": \"\"\"In the recent article titled 'AI adoption in industry,'\n",
    " key points addressed include the growing interest ... However, the\n",
    " author, Dr. Jane Smith, ...\"\"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data with LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Person(name='Bob', age=25, location='New York', hobby='playing basketball'), Person(name='Sarah', age=30, location='San Francisco', hobby='playing tennis')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Make sure to use a recent model that supports tools:\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    age: int = Field(description=\"The age of the person\")\n",
    "    location: str = Field(description=\"The location of the person\")\n",
    "    hobby: str = Field(description=\"The hobby of the person\")\n",
    "\n",
    "\n",
    "structured_llm = model.with_structured_output(Person)\n",
    "\n",
    "result = []\n",
    "result.append(structured_llm.invoke('''Bob is 25 years old. He lives in New York.\n",
    "He likes to play basketball.'''))\n",
    "result.append(structured_llm.invoke('''Sarah is 30 years old. She lives in San\n",
    "Francisco. She likes to play tennis.'''))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Planner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers.pydantic import PydanticOutputParser\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Query(BaseModel):\n",
    "    id: int\n",
    "    question: str\n",
    "    dependencies: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"\"\"A list of sub-queries that must be completed before\n",
    " this task can be completed.\n",
    " Use a sub query when anything is unknown and we might need to ask\n",
    " many queries to get an answer.\n",
    " Dependencies must only be other queries.\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "class QueryPlan(BaseModel):\n",
    "    query_graph: List[Query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query(id=1, question='I want to get the results from my database.', dependencies=[]), Query(id=2, question='I want to find out what the average age of my top 10 customers is.', dependencies=[1]), Query(id=3, question='I want to send an email to John.', dependencies=[2]), Query(id=4, question='I just generally want to send a welcome introduction email to Sarah.', dependencies=[])]\n"
     ]
    }
   ],
   "source": [
    "# Set up a chat model:\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Set up a parser:\n",
    "parser = PydanticOutputParser(pydantic_object=QueryPlan)\n",
    "template = \"\"\"Generate a query plan. This will be used for task execution.\n",
    "Answer the following query: {query}\n",
    "Return the following query graph format:\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
    "\n",
    "# Create the LCEL chain with the prompt, model, and parser:\n",
    "chain = chat_prompt | model | parser\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"query\": '''I want to get the results from my database. Then I want to find\n",
    "out what the average age of my top 10 customers is. Once I have the average\n",
    "age, I want to send an email to John. Also I just generally want to send a\n",
    "welcome introduction email to Sarah, regardless of the other tasks.''',\n",
    "    \"format_instructions\": parser.get_format_instructions()})\n",
    "\n",
    "print(result.query_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-vector_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
