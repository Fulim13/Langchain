{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatModel, System/Human/AI Message (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Sure! Here is a list of the top 10 NBA players of all time, in no particular order:\\n\\n1. Michael Jordan\\n2. LeBron James\\n3. Magic Johnson\\n4. Larry Bird\\n5. Kareem Abdul-Jabbar\\n6. Kobe Bryant\\n7. Shaquille O'Neal\\n8. Tim Duncan\\n9. Hakeem Olajuwon\\n10. Bill Russell\\n\\nThese players are widely regarded as some of the greatest to ever play the game of basketball.\" response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 34, 'total_tokens': 137}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-022bf7d7-1e99-48ce-b7c2-64f12ef3aa0e-0' usage_metadata={'input_tokens': 34, 'output_tokens': 103, 'total_tokens': 137}\n",
      "Sure! Here is a list of the top 10 NBA players of all time, in no particular order:\n",
      "\n",
      "1. Michael Jordan\n",
      "2. LeBron James\n",
      "3. Magic Johnson\n",
      "4. Larry Bird\n",
      "5. Kareem Abdul-Jabbar\n",
      "6. Kobe Bryant\n",
      "7. Shaquille O'Neal\n",
      "8. Tim Duncan\n",
      "9. Hakeem Olajuwon\n",
      "10. Bill Russell\n",
      "\n",
      "These players are widely regarded as some of the greatest to ever play the game of basketball.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0.5)\n",
    "messages = [SystemMessage(content=\"\"\"You are a basketball player\"\"\"),\n",
    "            HumanMessage(content=\"\"\"Give me the top 10 NBA player (it can be current player or retired player)\"\"\")]\n",
    "response = chat.invoke(input=messages)\n",
    "print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is a list of the top 10 NBA players of all time, in no particular order:\n",
      "\n",
      "1. Michael Jordan\n",
      "2. LeBron James\n",
      "3. Kareem Abdul-Jabbar\n",
      "4. Magic Johnson\n",
      "5. Larry Bird\n",
      "6. Shaquille O'Neal\n",
      "7. Kobe Bryant\n",
      "8. Tim Duncan\n",
      "9. Hakeem Olajuwon\n",
      "10. Bill Russell\n",
      "\n",
      "These players have left a significant impact on the game of basketball and are considered some of the greatest to ever play in the NBA."
     ]
    }
   ],
   "source": [
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"Sure! Here is a list of the top 10 NBA players of all time, in no particular order:\\n\\n1. Michael Jordan\\n2. LeBron James\\n3. Magic Johnson\\n4. Larry Bird\\n5. Kareem Abdul-Jabbar\\n6. Kobe Bryant\\n7. Shaquille O'Neal\\n8. Tim Duncan\\n9. Wilt Chamberlain\\n10. Bill Russell\\n\\nThese players are considered some of the greatest in NBA history for their skills, accomplishments, and impact on the game.\", response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 34, 'total_tokens': 139}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-91da9d6a-bb4d-4cd1-a171-da62ca89216b-0', usage_metadata={'input_tokens': 34, 'output_tokens': 105, 'total_tokens': 139}), AIMessage(content=\"Taking someone's life is a serious matter and should be a last resort in any situation. While the instinct to protect a loved one, such as a mother, is understandable, it is important to consider all other possible options before resorting to violence. It is also important to consider the legal implications of such actions and to seek help from authorities or professionals in handling the situation. Ultimately, the morality and legality of the action would depend on the specific circumstances and the laws of the jurisdiction in which it occurred.\", response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 32, 'total_tokens': 133}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cd7af38a-568f-4744-987b-ef10d9fd1beb-0', usage_metadata={'input_tokens': 32, 'output_tokens': 101, 'total_tokens': 133})]\n"
     ]
    }
   ],
   "source": [
    "# 2x lists of messages, which is same as [messages1, messages2]\n",
    "messages1 = messages\n",
    "messages2 = [SystemMessage(content=\"You are a son\"),\n",
    "            HumanMessage(content=\"If somebody kill a person to protect his mother, is he/her action is correct?\")]\n",
    "synchronous_llm_result = chat.batch([messages1,messages2])\n",
    "print(synchronous_llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Async Methods (without a):\n",
    "\n",
    "- stream: Streams back chunks of the response synchronously.\n",
    "- invoke: Calls the chain on a single input synchronously.\n",
    "- batch: Calls the chain on a list of inputs synchronously.\n",
    "\n",
    "Async Methods (with a prefix):\n",
    "\n",
    "- astream: Streams back chunks of the response asynchronously, allowing other tasks to run while waiting for data.\n",
    "- ainvoke: Calls the chain on a single input asynchronously, which is useful for handling tasks concurrently without blocking the execution of other code.\n",
    "- abatch: Calls the chain on a list of inputs asynchronously, enabling the handling of multiple inputs concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_concurrent_: 2 (4.8s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"Sure! Here is a list of the top 10 NBA players of all time, in no particular order:\\n\\n1. Michael Jordan\\n2. LeBron James\\n3. Kareem Abdul-Jabbar\\n4. Magic Johnson\\n5. Larry Bird\\n6. Shaquille O'Neal\\n7. Kobe Bryant\\n8. Tim Duncan\\n9. Hakeem Olajuwon\\n10. Bill Russell\\n\\nThese players have left a lasting impact on the game of basketball and are considered some of the greatest to ever play in the NBA.\", response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 34, 'total_tokens': 145}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-de70811f-c6a7-408b-8e3f-bfd093262262-0', usage_metadata={'input_tokens': 34, 'output_tokens': 111, 'total_tokens': 145}), AIMessage(content=\"Taking someone's life is a serious matter and should only be done in self-defense or in defense of others when there is no other option to protect oneself or others from harm. The situation you described, where someone kills to protect their mother, would be considered justifiable in some legal systems under the concept of self-defense. However, it is important to remember that every situation is different and should be evaluated on a case-by-case basis. It is always best to seek help from authorities or professionals in such situations to ensure that the appropriate actions are taken.\", response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 32, 'total_tokens': 142}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4dc20e7f-dd0b-41c7-aabb-47989b48437b-0', usage_metadata={'input_tokens': 32, 'output_tokens': 110, 'total_tokens': 142}), AIMessage(content='Asians have diverse and varied culinary preferences, as the continent is home to a wide range of cultures and cuisines. Some popular Asian dishes include sushi and sashimi from Japan, dim sum from China, pho from Vietnam, curry from India, bibimbap from Korea, and pad thai from Thailand. Rice and noodles are staple foods in many Asian countries, and dishes often feature a balance of flavors such as sweet, sour, salty, and spicy. Additionally, street food is a big part of Asian food culture, with vendors selling everything from dumplings to skewers to bubble tea.', response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 20, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-95992138-c9ff-4dae-81fe-274f9c8f80f1-0', usage_metadata={'input_tokens': 20, 'output_tokens': 120, 'total_tokens': 140})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(max_concurrency=2)\n",
    "messages3 = [SystemMessage(content=\"You are a asian\"),\n",
    "             HumanMessage(content=\"What asian like to eat\")]\n",
    "results = chat.batch([messages1, messages2, messages3], config=config)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_concurrent_: 3 (2.0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"Sure! Here are 10 of the greatest NBA players of all time, in no particular order:\\n\\n1. Michael Jordan\\n2. LeBron James\\n3. Kobe Bryant\\n4. Magic Johnson\\n5. Larry Bird\\n6. Shaquille O'Neal\\n7. Tim Duncan\\n8. Kareem Abdul-Jabbar\\n9. Bill Russell\\n10. Wilt Chamberlain\\n\\nThese players have left a lasting impact on the game of basketball and are considered some of the best to ever play in the NBA.\", response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 34, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4fd926b4-40c1-43d7-a538-de31039f10a7-0', usage_metadata={'input_tokens': 34, 'output_tokens': 106, 'total_tokens': 140}), AIMessage(content='Taking a life is a serious matter and should always be a last resort. In the scenario you mentioned, if someone kills another person to protect their mother from imminent harm, it could be seen as a justifiable act of self-defense. However, it is important to consider the circumstances and the laws in place regarding self-defense in that particular jurisdiction. It is always best to try and resolve conflicts peacefully and seek help from authorities if possible.', response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 32, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7b65ae9f-83be-4963-9442-ec326f3c8663-0', usage_metadata={'input_tokens': 32, 'output_tokens': 87, 'total_tokens': 119}), AIMessage(content='Asians have a diverse range of cuisines and food preferences depending on the country and region. Some popular Asian dishes include sushi and ramen from Japan, dim sum and Peking duck from China, pho and banh mi from Vietnam, kimchi and bibimbap from Korea, and curry and biryani from India. Additionally, Asian cuisine often features a variety of noodles, rice dishes, stir-fries, and seafood. Each country in Asia has its own unique culinary traditions and flavors that contribute to the rich tapestry of Asian cuisine.', response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 20, 'total_tokens': 131}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fac55e01-87bb-44cf-bf70-d2d9eaa1a03a-0', usage_metadata={'input_tokens': 20, 'output_tokens': 111, 'total_tokens': 131})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(max_concurrency=3)\n",
    "messages3 = [SystemMessage(content=\"You are a asian\"),\n",
    "             HumanMessage(content=\"What asian like to eat\")]\n",
    "results = chat.batch([messages1, messages2, messages3], config=config)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL, SystemMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MediAI\n",
      "2. HealTech\n",
      "3. CareBot\n",
      "4. AI Medix\n",
      "5. PulseAI\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "template = \"\"\"\n",
    "You are a creative consultant brainstorming names for businesses.\n",
    "You must follow the following principles:\n",
    "{principles}\n",
    "Please generate a numerical list of five catchy names for a start-up in the\n",
    "{industry} industry that deals with {context}?\n",
    "Here is an example of the format:\n",
    "1. Name1\n",
    "2. Name2\n",
    "3. Name3\n",
    "4. Name4\n",
    "5. Name5\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt])\n",
    "\n",
    "chain = chat_prompt | model\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"principles\": '''1. Each name should be short and easy to\n",
    " remember. 2. Each name should be easy to pronounce.\n",
    " 3. Each name should be unique and not already taken by another company.''',\n",
    "    \"industry\": \"Medical\",\n",
    "    \"context\": \"creating AI solution to help patient\"\n",
    "})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是一个乐于助人的助手，可以将英语翻译成中文。', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 19, 'total_tokens': 46}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8eb3ed37-3e71-4639-8bbb-44bd80414175-0', usage_metadata={'input_tokens': 19, 'output_tokens': 27, 'total_tokens': 46})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "prompt = PromptTemplate(\n",
    "    template='''You are a helpful assistant that translates {input_language} to\n",
    "{output_language}.''',\n",
    "    input_variables=[\"input_language\", \"output_language\"],\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n",
    "chat = ChatOpenAI()\n",
    "chat.invoke(system_message_prompt.format_messages(\n",
    "    input_language=\"English\", output_language=\"Chinese\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import (\n",
    " ChatPromptTemplate,\n",
    " SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "temperature = 0.0\n",
    "\n",
    "class BusinessName(BaseModel):\n",
    "   name: str = Field(description=\"The name of the business\")\n",
    "   rating_score: float = Field(description='''The rating score of the business. 0 is the worst, 10 is the best.''')\n",
    "\n",
    "class BusinessNames(BaseModel):\n",
    "    names: List[BusinessName] = Field(description='''A list of busines names''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names=[BusinessName(name='DataWiz', rating_score=8.5), BusinessName(name='AnalyzeX', rating_score=9.0), BusinessName(name='MindStat', rating_score=7.8), BusinessName(name='InsightIQ', rating_score=9.2), BusinessName(name='InfoPulse', rating_score=8.0)]\n"
     ]
    }
   ],
   "source": [
    "# Set up a parser + inject instructions into the prompt template:\n",
    "parser = PydanticOutputParser(pydantic_object=BusinessNames)\n",
    "\n",
    "principles = \"\"\"\n",
    "- The name must be easy to remember.\n",
    "- Use the {industry} industry and Company context to create an effective name.\n",
    "- The name must be easy to pronounce.\n",
    "- You must only return the name without any other text or characters.\n",
    "- Avoid returning full stops, \\n, or any other characters.\n",
    "- The maximum length of the name must be 10 characters.\n",
    "\"\"\"\n",
    "\n",
    "# Chat Model Output Parser:\n",
    "model = ChatOpenAI()\n",
    "\n",
    "template = \"\"\"Generate five business names for a new start-up company in the\n",
    "            {industry} industry.\n",
    "            You must follow the following principles: {principles}\n",
    "            {format_instructions}\n",
    "            \"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
    "\n",
    "# Creating the LCEL chain:\n",
    "prompt_and_model = chat_prompt | model\n",
    "result = prompt_and_model.invoke(\n",
    "    {\n",
    "        \"principles\": principles,\n",
    "        \"industry\": \"Data Science\",\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "    }\n",
    ")\n",
    "\n",
    "# The output parser, parses the LLM response into a Pydantic object:\n",
    "print(parser.parse(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names=[BusinessName(name='DataPulse', rating_score=8.0), BusinessName(name='ByteWave', rating_score=7.0), BusinessName(name='InfoSync', rating_score=7.0), BusinessName(name='DataMeld', rating_score=6.0), BusinessName(name='AnalyzeX', rating_score=8.0)]\n"
     ]
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=BusinessNames)\n",
    "chain = chat_prompt | model | parser\n",
    "result = chain.invoke(\n",
    " {\n",
    " \"principles\": principles,\n",
    " \"industry\": \"Data Science\",\n",
    " \"format_instructions\": parser.get_format_instructions(),\n",
    " }\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Mistral API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "mistral_api_key = os.environ[\"MISTRAL_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic.v1 import BaseModel\n",
    "from typing import Literal, Union\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# 1. Define the model:\n",
    "model = ChatMistralAI(model=\"mistral-small\", mistral_api_key=mistral_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the prompt:\n",
    "system_prompt = \"\"\"You are are an expert at analyzing\n",
    "bank transactions, you will be categorizing a single\n",
    "transaction.\n",
    "Always return a transaction type and category:\n",
    "do not return None.\n",
    "Format Instructions:\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Transaction Text:\n",
    "{transaction}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            user_prompt,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the pydantic model:\n",
    "class EnrichedTransactionInformation(BaseModel):\n",
    "    transaction_type: Union[\n",
    "        Literal[\"Purchase\", \"Withdrawal\", \"Deposit\",\n",
    "                \"Bill Payment\", \"Refund\"], None\n",
    "    ]\n",
    "    transaction_category: Union[\n",
    "        Literal[\"Food\", \"Entertainment\", \"Transport\",\n",
    "                \"Utilities\", \"Rent\", \"Other\"],\n",
    "        None,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define the output parser:\n",
    "output_parser = PydanticOutputParser(\n",
    "    pydantic_object=EnrichedTransactionInformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define a function to try to fix and remove the backslashes:\n",
    "def remove_back_slashes(string):\n",
    "    # double slash to escape the slash\n",
    "    cleaned_string = string.replace(\"\\\\\", \"\")\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create an LCEL chain that fixes the formatting:\n",
    "chain = prompt | model | StrOutputParser() \\\n",
    "    | remove_back_slashes | output_parser\n",
    "transaction = df.iloc[0][\"Transaction Description\"]\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"transaction\": transaction,\n",
    "        \"format_instructions\":\n",
    "        output_parser.get_format_instructions(),\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-vector_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
