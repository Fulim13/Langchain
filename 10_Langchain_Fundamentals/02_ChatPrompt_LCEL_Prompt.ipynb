{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Chat Prompt Templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['category', 'context', 'principles'], template='You are a creative writer who knows how to brainstorming names for books.\\n\\nYou must follow these principles:\\n{principles}\\n\\nGenerate a numerical list of 5 names for a book in the {category} category that with the idea of {context} with score beside its name\\n')\n",
      "\n",
      "input_variables=['category', 'context', 'principles'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['category', 'context', 'principles'], template='You are a creative writer who knows how to brainstorming names for books.\\n\\nYou must follow these principles:\\n{principles}\\n\\nGenerate a numerical list of 5 names for a book in the {category} category that with the idea of {context} with score beside its name\\n'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "template = \"\"\"You are a creative writer who knows how to brainstorming names for books.\n",
    "\n",
    "You must follow these principles:\n",
    "{principles}\n",
    "\n",
    "Generate a numerical list of 5 names for a book in the {category} category that with the idea of {context} with score beside its name\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(template=template)\n",
    "print(system_prompt)\n",
    "\n",
    "print()\n",
    "\n",
    "user_prompt = ChatPromptTemplate.from_messages([system_prompt])\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LCEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = user_prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Invoke LCEL Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"principles\":\n",
    "\n",
    "1. Each name should be short and easy to remember.\n",
    "2. Each name should be easy to pronounce.\n",
    "3. Each name should be unique and not already taken by others.\n",
    "\n",
    "\"category\": Productivity\n",
    "\n",
    "\"context\": Active Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\n",
    "    \"principles\": \"\"\"\n",
    "        1. Each name should be short and easy to remember.\n",
    "        2. Each name should be easy to pronounce.\n",
    "        3. Each name should be unique and not already taken by others.\n",
    "    \"\"\",\n",
    "    \"category\": \"Productivity\",\n",
    "    \"context\": \"Active Recall\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"MindPrompt\" - Score: 8\n",
      "2. \"RecallBoost\" - Score: 7\n",
      "3. \"RapidRemind\" - Score: 6\n",
      "4. \"QuickRecap\" - Score: 7\n",
      "5. \"ActiveEcho\" - Score: 8\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PromptTemplate with Chat Models With format_messages and Without LCEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我目前正在学习LangChain和LangGraph\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a helpful assistance to translate the context from {input_language} to {output_language}\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "    \"\"\",\n",
    "    input_variables=[\"input_language\", \"output_language\", \"context\"]\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n",
    "\n",
    "response = model.invoke(system_message_prompt.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Mandarin\",\n",
    "    context=\"I currentl learning LangChain and LangGraph\"\n",
    "))\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-vector_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
